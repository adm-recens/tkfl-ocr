{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15be5621",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline for Enhanced OCR Accuracy (PyTorch)\n",
    "\n",
    "This notebook demonstrates how to build and train a machine learning model to improve OCR accuracy and data extraction from receipts using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc33a1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "We will use PyTorch, torchvision, pandas, and PIL for data handling, model building, and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eee3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f2275",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataset\n",
    "Load receipt images and their OCR text from the uploads folder and database. Preprocess images and text for model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89271126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load OCR data from SQLite and images from uploads folder\n",
    "import sqlite3\n",
    "DB_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'ocr.sqlite3')\n",
    "UPLOADS_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'uploads')\n",
    "\n",
    "def load_ocr_data():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT file_name, raw_ocr, parsed_json FROM vouchers_master')\n",
    "    data = cur.fetchall()\n",
    "    conn.close()\n",
    "    return data\n",
    "\n",
    "data = load_ocr_data()\n",
    "print(f\"Loaded {len(data)} records from DB.\")\n",
    "\n",
    "# Example transform for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class ReceiptDataset(Dataset):\n",
    "    def __init__(self, data, uploads_path, transform=None):\n",
    "        self.data = data\n",
    "        self.uploads_path = uploads_path\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        file_name, raw_ocr, parsed_json = self.data[idx]\n",
    "        img_path = os.path.join(self.uploads_path, file_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # For demo: use raw_ocr as target (could be structured fields)\n",
    "        return image, raw_ocr\n",
    "\n",
    "dataset = ReceiptDataset(data, UPLOADS_PATH, transform)\n",
    "print(f\"Dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86100b3",
   "metadata": {},
   "source": [
    "## 3. Create DataLoader for Batching\n",
    "Use DataLoader to efficiently batch and shuffle data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8acb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Example: iterate through one batch\n",
    "for images, targets in dataloader:\n",
    "    print(f\"Batch images shape: {images.shape}\")\n",
    "    print(f\"Batch targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47744d",
   "metadata": {},
   "source": [
    "## 4. Define Neural Network Model\n",
    "Implement a simple CNN+RNN model for document understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleOCRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Linear(32 * 64 * 64, 128)\n",
    "        self.out = nn.Linear(128, 1)  # For demo: regression on OCR text length\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleOCRModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3cc00a",
   "metadata": {},
   "source": [
    "## 5. Set Up Loss Function and Optimizer\n",
    "Choose a loss function and optimizer for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# For demo: target is OCR text length (regression)\n",
    "def ocr_target(text):\n",
    "    return torch.tensor([len(text)], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5199a",
   "metadata": {},
   "source": [
    "## 6. Batch Training Loop\n",
    "Train the model using batches of data, updating weights and tracking loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d28ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        batch_targets = torch.stack([ocr_target(t) for t in targets])\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5ce42",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance\n",
    "Assess the trained model's accuracy or loss on a validation or test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    for images, targets in dataloader:\n",
    "        outputs = model(images)\n",
    "        batch_targets = torch.stack([ocr_target(t) for t in targets])\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
